{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "igMyGnjE9hEp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing dataset to obtain relevant gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dataset = {}\n",
    "with open('model/keypoint_classifier/keypoint.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        gesture_id = int(row[0])\n",
    "        if gesture_id not in current_dataset:\n",
    "            current_dataset[gesture_id] = []\n",
    "        \n",
    "        current_dataset[gesture_id].append(row[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595\n",
      "1663\n",
      "1510\n",
      "672\n",
      "164\n",
      "257\n",
      "139\n",
      "190\n",
      "\n",
      "1595\n",
      "1663\n",
      "1510\n",
      "672\n",
      "164\n",
      "139\n",
      "190\n"
     ]
    }
   ],
   "source": [
    "for gesture in current_dataset.keys():\n",
    "    print(len(current_dataset[gesture]))\n",
    "    \n",
    "print()\n",
    "    \n",
    "with open('model/keypoint_classifier/keypoint_processed.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    current_gesture = 0\n",
    "    for gesture in current_dataset.keys():\n",
    "        if gesture != 5:\n",
    "            for sample in current_dataset[gesture]:\n",
    "                writer.writerow([str(current_gesture)] + sample)\n",
    "            \n",
    "            current_gesture += 1\n",
    "\n",
    "new_dataset = {}\n",
    "with open('model/keypoint_classifier/keypoint_processed.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        gesture_id = int(row[0])\n",
    "        if gesture_id not in new_dataset:\n",
    "            new_dataset[gesture_id] = []\n",
    "        \n",
    "        new_dataset[gesture_id].append(row[1:])\n",
    "\n",
    "for gesture in new_dataset.keys():\n",
    "    print(len(new_dataset[gesture]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2HDvhIu9hEr"
   },
   "source": [
    "# Specify each path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9NvZP2Zn9hEy"
   },
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "dataset = 'model/keypoint_classifier/keypoint_processed.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier.hdf5'\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5oMH7x19hEz"
   },
   "source": [
    "# Set number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "du4kodXL9hEz"
   },
   "outputs": [],
   "source": [
    "# Change training classes if necessary\n",
    "NUM_CLASSES = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjnL0uso9hEz"
   },
   "source": [
    "# Dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QT5ZqtEz9hE0"
   },
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QmoKFsp49hE0"
   },
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xQU7JTZ_9hE0"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.70, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "xElG5FoPDQO9",
    "outputId": "2ef372ed-62e3-49c1-ad36-a5b5dc76701a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6]), array([1595, 1663, 1510,  672,  164,  139,  190], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classes count\n",
    "counts = np.unique(y_dataset, return_counts=True)\n",
    "df = pd.DataFrame(counts)\n",
    "graph = df.T.plot(kind=\"bar\", stacked=True, title='Number of gestures per class')\n",
    "graph.set_xlabel(\"Class ID\")\n",
    "graph.set_ylabel(\"Count\")\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxK_lETT9hE0"
   },
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "vHBmUf1t9hE1"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.0),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ypqky9tc9hE1",
    "outputId": "c42f3550-ceee-45b8-d40d-d99fd84a2616"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dropout_9 (Dropout)         (None, 42)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                1376      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 231       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,719\n",
      "Trainable params: 3,719\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "MbMjOflQ9hE1"
   },
   "outputs": [],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "c3Dac0M_9hE2"
   },
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XI0j1Iu9hE2"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WirBl-JE9hE3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 1.7198 - accuracy: 0.3328\n",
      "Epoch 00001: val_loss improved from inf to 1.31104, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 2s 13ms/step - loss: 1.6627 - accuracy: 0.3441 - val_loss: 1.3110 - val_accuracy: 0.5303\n",
      "Epoch 2/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 1.0141 - accuracy: 0.7054\n",
      "Epoch 00002: val_loss improved from 1.31104 to 0.70686, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 1.0009 - accuracy: 0.7098 - val_loss: 0.7069 - val_accuracy: 0.8309\n",
      "Epoch 3/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.5196 - accuracy: 0.8648\n",
      "Epoch 00003: val_loss improved from 0.70686 to 0.36997, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.5125 - accuracy: 0.8661 - val_loss: 0.3700 - val_accuracy: 0.9062\n",
      "Epoch 4/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.2856 - accuracy: 0.9311\n",
      "Epoch 00004: val_loss improved from 0.36997 to 0.23402, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 8ms/step - loss: 0.2813 - accuracy: 0.9321 - val_loss: 0.2340 - val_accuracy: 0.9511\n",
      "Epoch 5/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1814 - accuracy: 0.9656\n",
      "Epoch 00005: val_loss improved from 0.23402 to 0.16985, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.1811 - accuracy: 0.9656 - val_loss: 0.1698 - val_accuracy: 0.9612\n",
      "Epoch 6/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.1323 - accuracy: 0.9763\n",
      "Epoch 00006: val_loss improved from 0.16985 to 0.13586, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1319 - accuracy: 0.9762 - val_loss: 0.1359 - val_accuracy: 0.9674\n",
      "Epoch 7/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.1068 - accuracy: 0.9803\n",
      "Epoch 00007: val_loss improved from 0.13586 to 0.11461, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9807 - val_loss: 0.1146 - val_accuracy: 0.9764\n",
      "Epoch 8/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0863 - accuracy: 0.9852\n",
      "Epoch 00008: val_loss improved from 0.11461 to 0.10218, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0877 - accuracy: 0.9848 - val_loss: 0.1022 - val_accuracy: 0.9792\n",
      "Epoch 9/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0748 - accuracy: 0.9866\n",
      "Epoch 00009: val_loss improved from 0.10218 to 0.08813, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9860 - val_loss: 0.0881 - val_accuracy: 0.9803\n",
      "Epoch 10/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0639 - accuracy: 0.9869\n",
      "Epoch 00010: val_loss improved from 0.08813 to 0.07963, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9875 - val_loss: 0.0796 - val_accuracy: 0.9809\n",
      "Epoch 11/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0594 - accuracy: 0.9889\n",
      "Epoch 00011: val_loss improved from 0.07963 to 0.07855, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9889 - val_loss: 0.0785 - val_accuracy: 0.9826\n",
      "Epoch 12/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0594 - accuracy: 0.9872\n",
      "Epoch 00012: val_loss improved from 0.07855 to 0.07107, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9875 - val_loss: 0.0711 - val_accuracy: 0.9815\n",
      "Epoch 13/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0499 - accuracy: 0.9912\n",
      "Epoch 00013: val_loss improved from 0.07107 to 0.06887, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0471 - accuracy: 0.9923 - val_loss: 0.0689 - val_accuracy: 0.9848\n",
      "Epoch 14/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0452 - accuracy: 0.9912\n",
      "Epoch 00014: val_loss did not improve from 0.06887\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9913 - val_loss: 0.0752 - val_accuracy: 0.9809\n",
      "Epoch 15/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0376 - accuracy: 0.9931\n",
      "Epoch 00015: val_loss improved from 0.06887 to 0.05528, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0407 - accuracy: 0.9921 - val_loss: 0.0553 - val_accuracy: 0.9871\n",
      "Epoch 16/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9916\n",
      "Epoch 00016: val_loss did not improve from 0.05528\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0418 - accuracy: 0.9916 - val_loss: 0.0588 - val_accuracy: 0.9860\n",
      "Epoch 17/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9928\n",
      "Epoch 00017: val_loss improved from 0.05528 to 0.05391, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9923 - val_loss: 0.0539 - val_accuracy: 0.9860\n",
      "Epoch 18/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0368 - accuracy: 0.9931\n",
      "Epoch 00018: val_loss improved from 0.05391 to 0.04957, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0338 - accuracy: 0.9937 - val_loss: 0.0496 - val_accuracy: 0.9876\n",
      "Epoch 19/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0286 - accuracy: 0.9937\n",
      "Epoch 00019: val_loss improved from 0.04957 to 0.04812, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0303 - accuracy: 0.9940 - val_loss: 0.0481 - val_accuracy: 0.9876\n",
      "Epoch 20/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9930\n",
      "Epoch 00020: val_loss did not improve from 0.04812\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9930 - val_loss: 0.0482 - val_accuracy: 0.9871\n",
      "Epoch 21/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9944\n",
      "Epoch 00021: val_loss did not improve from 0.04812\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0267 - accuracy: 0.9945 - val_loss: 0.0495 - val_accuracy: 0.9871\n",
      "Epoch 22/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9954\n",
      "Epoch 00022: val_loss improved from 0.04812 to 0.04664, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0256 - accuracy: 0.9954 - val_loss: 0.0466 - val_accuracy: 0.9882\n",
      "Epoch 23/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9940\n",
      "Epoch 00023: val_loss improved from 0.04664 to 0.04011, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0246 - accuracy: 0.9940 - val_loss: 0.0401 - val_accuracy: 0.9876\n",
      "Epoch 24/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0230 - accuracy: 0.9956\n",
      "Epoch 00024: val_loss did not improve from 0.04011\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0238 - accuracy: 0.9954 - val_loss: 0.0406 - val_accuracy: 0.9876\n",
      "Epoch 25/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0249 - accuracy: 0.9950\n",
      "Epoch 00025: val_loss did not improve from 0.04011\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0239 - accuracy: 0.9957 - val_loss: 0.0476 - val_accuracy: 0.9882\n",
      "Epoch 26/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9949\n",
      "Epoch 00026: val_loss did not improve from 0.04011\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0422 - val_accuracy: 0.9876\n",
      "Epoch 27/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9952\n",
      "Epoch 00027: val_loss improved from 0.04011 to 0.03497, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0219 - accuracy: 0.9952 - val_loss: 0.0350 - val_accuracy: 0.9893\n",
      "Epoch 28/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9951\n",
      "Epoch 00028: val_loss did not improve from 0.03497\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0214 - accuracy: 0.9949 - val_loss: 0.0427 - val_accuracy: 0.9904\n",
      "Epoch 29/1000\n",
      "51/65 [======================>.......] - ETA: 0s - loss: 0.0171 - accuracy: 0.9963\n",
      "Epoch 00029: val_loss did not improve from 0.03497\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9961 - val_loss: 0.0382 - val_accuracy: 0.9893\n",
      "Epoch 30/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0133 - accuracy: 0.9972\n",
      "Epoch 00030: val_loss improved from 0.03497 to 0.03243, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0184 - accuracy: 0.9961 - val_loss: 0.0324 - val_accuracy: 0.9910\n",
      "Epoch 31/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.9969\n",
      "Epoch 00031: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0177 - accuracy: 0.9969 - val_loss: 0.0347 - val_accuracy: 0.9893\n",
      "Epoch 32/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0156 - accuracy: 0.9971\n",
      "Epoch 00032: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.0411 - val_accuracy: 0.9876\n",
      "Epoch 33/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0158 - accuracy: 0.9969\n",
      "Epoch 00033: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0449 - val_accuracy: 0.9888\n",
      "Epoch 34/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0141 - accuracy: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0144 - accuracy: 0.9974 - val_loss: 0.0349 - val_accuracy: 0.9882\n",
      "Epoch 35/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9964\n",
      "Epoch 00035: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0147 - accuracy: 0.9964 - val_loss: 0.0352 - val_accuracy: 0.9882\n",
      "Epoch 36/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0131 - accuracy: 0.9971\n",
      "Epoch 00036: val_loss did not improve from 0.03243\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0377 - val_accuracy: 0.9876\n",
      "Epoch 37/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0157 - accuracy: 0.9969\n",
      "Epoch 00037: val_loss improved from 0.03243 to 0.03135, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9971 - val_loss: 0.0313 - val_accuracy: 0.9910\n",
      "Epoch 38/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 0.03135\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0425 - val_accuracy: 0.9888\n",
      "Epoch 39/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9966\n",
      "Epoch 00039: val_loss improved from 0.03135 to 0.03114, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.0311 - val_accuracy: 0.9893\n",
      "Epoch 40/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0115 - accuracy: 0.9979\n",
      "Epoch 00040: val_loss improved from 0.03114 to 0.02780, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.0278 - val_accuracy: 0.9899\n",
      "Epoch 41/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0120 - accuracy: 0.9974\n",
      "Epoch 00041: val_loss improved from 0.02780 to 0.02683, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9974 - val_loss: 0.0268 - val_accuracy: 0.9921\n",
      "Epoch 42/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 0.0110 - accuracy: 0.9976\n",
      "Epoch 00042: val_loss did not improve from 0.02683\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0311 - val_accuracy: 0.9899\n",
      "Epoch 43/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9968\n",
      "Epoch 00043: val_loss did not improve from 0.02683\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0109 - accuracy: 0.9969 - val_loss: 0.0297 - val_accuracy: 0.9921\n",
      "Epoch 44/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0103 - accuracy: 0.9973\n",
      "Epoch 00044: val_loss did not improve from 0.02683\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0095 - accuracy: 0.9976 - val_loss: 0.0275 - val_accuracy: 0.9938\n",
      "Epoch 45/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0117 - accuracy: 0.9970\n",
      "Epoch 00045: val_loss improved from 0.02683 to 0.02630, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0107 - accuracy: 0.9974 - val_loss: 0.0263 - val_accuracy: 0.9910\n",
      "Epoch 46/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0096 - accuracy: 0.9975\n",
      "Epoch 00046: val_loss did not improve from 0.02630\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.0300 - val_accuracy: 0.9910\n",
      "Epoch 47/1000\n",
      "54/65 [=======================>......] - ETA: 0s - loss: 0.0112 - accuracy: 0.9968\n",
      "Epoch 00047: val_loss did not improve from 0.02630\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9974 - val_loss: 0.0355 - val_accuracy: 0.9904\n",
      "Epoch 48/1000\n",
      "52/65 [=======================>......] - ETA: 0s - loss: 0.0096 - accuracy: 0.9979\n",
      "Epoch 00048: val_loss did not improve from 0.02630\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0103 - accuracy: 0.9976 - val_loss: 0.0359 - val_accuracy: 0.9888\n",
      "Epoch 49/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0090 - accuracy: 0.9979\n",
      "Epoch 00049: val_loss did not improve from 0.02630\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0297 - val_accuracy: 0.9933\n",
      "Epoch 50/1000\n",
      "52/65 [=======================>......] - ETA: 0s - loss: 0.0073 - accuracy: 0.9985\n",
      "Epoch 00050: val_loss improved from 0.02630 to 0.02431, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0078 - accuracy: 0.9986 - val_loss: 0.0243 - val_accuracy: 0.9921\n",
      "Epoch 51/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0087 - accuracy: 0.9978\n",
      "Epoch 00051: val_loss did not improve from 0.02431\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.0265 - val_accuracy: 0.9938\n",
      "Epoch 52/1000\n",
      "54/65 [=======================>......] - ETA: 0s - loss: 0.0063 - accuracy: 0.9988\n",
      "Epoch 00052: val_loss did not improve from 0.02431\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9988 - val_loss: 0.0245 - val_accuracy: 0.9938\n",
      "Epoch 53/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 0.0083 - accuracy: 0.9979\n",
      "Epoch 00053: val_loss did not improve from 0.02431\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.0314 - val_accuracy: 0.9893\n",
      "Epoch 54/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0097 - accuracy: 0.9971\n",
      "Epoch 00054: val_loss did not improve from 0.02431\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0096 - accuracy: 0.9971 - val_loss: 0.0294 - val_accuracy: 0.9916\n",
      "Epoch 55/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 00055: val_loss improved from 0.02431 to 0.02377, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0067 - accuracy: 0.9978 - val_loss: 0.0238 - val_accuracy: 0.9927\n",
      "Epoch 56/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0067 - accuracy: 0.9982\n",
      "Epoch 00056: val_loss did not improve from 0.02377\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0064 - accuracy: 0.9983 - val_loss: 0.0248 - val_accuracy: 0.9938\n",
      "Epoch 57/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0078 - accuracy: 0.9980\n",
      "Epoch 00057: val_loss did not improve from 0.02377\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0073 - accuracy: 0.9983 - val_loss: 0.0240 - val_accuracy: 0.9933\n",
      "Epoch 58/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0065 - accuracy: 0.9988\n",
      "Epoch 00058: val_loss improved from 0.02377 to 0.02196, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.0220 - val_accuracy: 0.9938\n",
      "Epoch 59/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9980\n",
      "Epoch 00059: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0250 - val_accuracy: 0.9944\n",
      "Epoch 60/1000\n",
      "54/65 [=======================>......] - ETA: 0s - loss: 0.0063 - accuracy: 0.9983\n",
      "Epoch 00060: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0251 - val_accuracy: 0.9938\n",
      "Epoch 61/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0069 - accuracy: 0.9974\n",
      "Epoch 00061: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.0242 - val_accuracy: 0.9938\n",
      "Epoch 62/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0055 - accuracy: 0.9987\n",
      "Epoch 00062: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.0231 - val_accuracy: 0.9938\n",
      "Epoch 63/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0061 - accuracy: 0.9984\n",
      "Epoch 00063: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0285 - val_accuracy: 0.9916\n",
      "Epoch 64/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0079 - accuracy: 0.9981\n",
      "Epoch 00064: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0078 - accuracy: 0.9981 - val_loss: 0.0256 - val_accuracy: 0.9938\n",
      "Epoch 65/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9983\n",
      "Epoch 00065: val_loss did not improve from 0.02196\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0245 - val_accuracy: 0.9955\n",
      "Epoch 66/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9974\n",
      "Epoch 00066: val_loss improved from 0.02196 to 0.02110, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0055 - accuracy: 0.9974 - val_loss: 0.0211 - val_accuracy: 0.9955\n",
      "Epoch 67/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 0.0038 - accuracy: 0.9997\n",
      "Epoch 00067: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9993 - val_loss: 0.0232 - val_accuracy: 0.9938\n",
      "Epoch 68/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 00068: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.0261 - val_accuracy: 0.9938\n",
      "Epoch 69/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987\n",
      "Epoch 00069: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0250 - val_accuracy: 0.9938\n",
      "Epoch 70/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9985\n",
      "Epoch 00070: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0053 - accuracy: 0.9986 - val_loss: 0.0270 - val_accuracy: 0.9933\n",
      "Epoch 71/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0040 - accuracy: 0.9992\n",
      "Epoch 00071: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0247 - val_accuracy: 0.9949\n",
      "Epoch 72/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0041 - accuracy: 0.9992\n",
      "Epoch 00072: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0256 - val_accuracy: 0.9938\n",
      "Epoch 73/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 00073: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.0220 - val_accuracy: 0.9955\n",
      "Epoch 74/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9985\n",
      "Epoch 00074: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0214 - val_accuracy: 0.9949\n",
      "Epoch 75/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980\n",
      "Epoch 00075: val_loss did not improve from 0.02110\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0051 - accuracy: 0.9981 - val_loss: 0.0229 - val_accuracy: 0.9938\n",
      "Epoch 76/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9975\n",
      "Epoch 00076: val_loss improved from 0.02110 to 0.02049, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0205 - val_accuracy: 0.9949\n",
      "Epoch 77/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00077: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 0.0234 - val_accuracy: 0.9949\n",
      "Epoch 78/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 00078: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.0255 - val_accuracy: 0.9933\n",
      "Epoch 79/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9990\n",
      "Epoch 00079: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.0208 - val_accuracy: 0.9949\n",
      "Epoch 80/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0064 - accuracy: 0.9984\n",
      "Epoch 00080: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.0270 - val_accuracy: 0.9938\n",
      "Epoch 81/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9985\n",
      "Epoch 00081: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0056 - accuracy: 0.9986 - val_loss: 0.0265 - val_accuracy: 0.9944\n",
      "Epoch 82/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0062 - accuracy: 0.9973\n",
      "Epoch 00082: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
      "Epoch 83/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9965\n",
      "Epoch 00083: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0108 - accuracy: 0.9966 - val_loss: 0.0399 - val_accuracy: 0.9927\n",
      "Epoch 84/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984\n",
      "Epoch 00084: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0236 - val_accuracy: 0.9949\n",
      "Epoch 85/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0210 - val_accuracy: 0.9955\n",
      "Epoch 86/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0041 - accuracy: 0.9985\n",
      "Epoch 00086: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.0249 - val_accuracy: 0.9933\n",
      "Epoch 87/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 00087: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0232 - val_accuracy: 0.9949\n",
      "Epoch 88/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9995\n",
      "Epoch 00088: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0244 - val_accuracy: 0.9949\n",
      "Epoch 89/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0039 - accuracy: 0.9985\n",
      "Epoch 00089: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9986 - val_loss: 0.0320 - val_accuracy: 0.9949\n",
      "Epoch 90/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0060 - accuracy: 0.9979\n",
      "Epoch 00090: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0063 - accuracy: 0.9976 - val_loss: 0.0270 - val_accuracy: 0.9916\n",
      "Epoch 91/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 00091: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.0255 - val_accuracy: 0.9949\n",
      "Epoch 92/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0025 - accuracy: 0.9995\n",
      "Epoch 00092: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0262 - val_accuracy: 0.9949\n",
      "Epoch 93/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9992\n",
      "Epoch 00093: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0222 - val_accuracy: 0.9961\n",
      "Epoch 94/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0063 - accuracy: 0.9969\n",
      "Epoch 00094: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 0.0308 - val_accuracy: 0.9944\n",
      "Epoch 95/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0051 - accuracy: 0.9985\n",
      "Epoch 00095: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.9986 - val_loss: 0.0338 - val_accuracy: 0.9933\n",
      "Epoch 96/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9993\n",
      "Epoch 00096: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0245 - val_accuracy: 0.9955\n",
      "Epoch 97/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990  \n",
      "Epoch 00097: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0261 - val_accuracy: 0.9961\n",
      "Epoch 98/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0038 - accuracy: 0.9988\n",
      "Epoch 00098: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0269 - val_accuracy: 0.9955\n",
      "Epoch 99/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9995\n",
      "Epoch 00099: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0233 - val_accuracy: 0.9966\n",
      "Epoch 100/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0030 - accuracy: 0.9994\n",
      "Epoch 00100: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0304 - val_accuracy: 0.9927\n",
      "Epoch 101/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 00101: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0256 - val_accuracy: 0.9955\n",
      "Epoch 102/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9993\n",
      "Epoch 00102: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0253 - val_accuracy: 0.9955\n",
      "Epoch 103/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 00103: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0246 - val_accuracy: 0.9955\n",
      "Epoch 104/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 00104: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0251 - val_accuracy: 0.9949\n",
      "Epoch 105/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0052 - accuracy: 0.9986\n",
      "Epoch 00105: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.0252 - val_accuracy: 0.9949\n",
      "Epoch 106/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 00106: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0301 - val_accuracy: 0.9949\n",
      "Epoch 107/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 00107: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0332 - val_accuracy: 0.9944\n",
      "Epoch 108/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0025 - accuracy: 0.9997\n",
      "Epoch 00108: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0266 - val_accuracy: 0.9944\n",
      "Epoch 109/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9993    \n",
      "Epoch 00109: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0236 - val_accuracy: 0.9944\n",
      "Epoch 110/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 00110: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0301 - val_accuracy: 0.9938\n",
      "Epoch 111/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998\n",
      "Epoch 00111: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0024 - accuracy: 0.9998 - val_loss: 0.0224 - val_accuracy: 0.9961\n",
      "Epoch 112/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 00112: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0257 - val_accuracy: 0.9955\n",
      "Epoch 113/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997    \n",
      "Epoch 00113: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0228 - val_accuracy: 0.9966\n",
      "Epoch 114/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997    \n",
      "Epoch 00114: val_loss did not improve from 0.02049\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0279 - val_accuracy: 0.9949\n",
      "Epoch 115/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995  \n",
      "Epoch 00115: val_loss improved from 0.02049 to 0.01984, saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0198 - val_accuracy: 0.9966\n",
      "Epoch 116/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 0.9998\n",
      "Epoch 00116: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9998 - val_loss: 0.0266 - val_accuracy: 0.9949\n",
      "Epoch 117/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
      "Epoch 00117: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0256 - val_accuracy: 0.9949\n",
      "Epoch 118/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0028 - accuracy: 0.9990    \n",
      "Epoch 00118: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 0.0232 - val_accuracy: 0.9966\n",
      "Epoch 119/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 00119: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0301 - val_accuracy: 0.9944\n",
      "Epoch 120/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 0.0169 - accuracy: 0.9947\n",
      "Epoch 00120: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0312 - val_accuracy: 0.9933\n",
      "Epoch 121/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 00121: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 0.9938\n",
      "Epoch 122/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9995    \n",
      "Epoch 00122: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 0.0275 - val_accuracy: 0.9949\n",
      "Epoch 123/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
      "Epoch 00123: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0269 - val_accuracy: 0.9938\n",
      "Epoch 124/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 6.6149e-04 - accuracy: 1.0000\n",
      "Epoch 00124: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9961\n",
      "Epoch 125/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00125: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0223 - val_accuracy: 0.9944\n",
      "Epoch 126/1000\n",
      "54/65 [=======================>......] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
      "Epoch 00126: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0222 - val_accuracy: 0.9961\n",
      "Epoch 127/1000\n",
      "51/65 [======================>.......] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000  \n",
      "Epoch 00127: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0204 - val_accuracy: 0.9961\n",
      "Epoch 128/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 00128: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0253 - val_accuracy: 0.9961\n",
      "Epoch 129/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0024 - accuracy: 0.9987\n",
      "Epoch 00129: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 0.0261 - val_accuracy: 0.9938\n",
      "Epoch 130/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998  \n",
      "Epoch 00130: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0296 - val_accuracy: 0.9949\n",
      "Epoch 131/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9991  \n",
      "Epoch 00131: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 0.0230 - val_accuracy: 0.9949\n",
      "Epoch 132/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00132: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0219 - val_accuracy: 0.9961\n",
      "Epoch 133/1000\n",
      "57/65 [=========================>....] - ETA: 0s - loss: 0.0019 - accuracy: 0.9995  \n",
      "Epoch 00133: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0233 - val_accuracy: 0.9955\n",
      "Epoch 134/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00134: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0208 - val_accuracy: 0.9949\n",
      "Epoch 135/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9978\n",
      "Epoch 00135: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.0325 - val_accuracy: 0.9955\n",
      "Epoch 136/1000\n",
      "52/65 [=======================>......] - ETA: 0s - loss: 0.0024 - accuracy: 0.9997\n",
      "Epoch 00136: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0254 - val_accuracy: 0.9966\n",
      "Epoch 137/1000\n",
      "61/65 [===========================>..] - ETA: 0s - loss: 0.0016 - accuracy: 0.9995\n",
      "Epoch 00137: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0214 - val_accuracy: 0.9955\n",
      "Epoch 138/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 00138: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0239 - val_accuracy: 0.9966\n",
      "Epoch 139/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0020 - accuracy: 0.9997  \n",
      "Epoch 00139: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0239 - val_accuracy: 0.9961\n",
      "Epoch 140/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
      "Epoch 00140: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0273 - val_accuracy: 0.9955\n",
      "Epoch 141/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00141: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0247 - val_accuracy: 0.9955\n",
      "Epoch 142/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0010 - accuracy: 0.9997\n",
      "Epoch 00142: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 9.6784e-04 - accuracy: 0.9998 - val_loss: 0.0240 - val_accuracy: 0.9966\n",
      "Epoch 143/1000\n",
      "62/65 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
      "Epoch 00143: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0226 - val_accuracy: 0.9955\n",
      "Epoch 144/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 00144: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 0.0237 - val_accuracy: 0.9955\n",
      "Epoch 145/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9992  \n",
      "Epoch 00145: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 0.0230 - val_accuracy: 0.9955\n",
      "Epoch 146/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 4.8303e-04 - accuracy: 1.0000\n",
      "Epoch 00146: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0253 - val_accuracy: 0.9961\n",
      "Epoch 147/1000\n",
      "63/65 [============================>.] - ETA: 0s - loss: 5.8971e-04 - accuracy: 0.9998\n",
      "Epoch 00147: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 5.7718e-04 - accuracy: 0.9998 - val_loss: 0.0240 - val_accuracy: 0.9961\n",
      "Epoch 148/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998    \n",
      "Epoch 00148: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0216 - val_accuracy: 0.9961\n",
      "Epoch 149/1000\n",
      "60/65 [==========================>...] - ETA: 0s - loss: 0.0055 - accuracy: 0.9982\n",
      "Epoch 00149: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0052 - accuracy: 0.9983 - val_loss: 0.0324 - val_accuracy: 0.9916\n",
      "Epoch 150/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
      "Epoch 00150: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.0255 - val_accuracy: 0.9933\n",
      "Epoch 151/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0028 - accuracy: 0.9989\n",
      "Epoch 00151: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.0279 - val_accuracy: 0.9955\n",
      "Epoch 152/1000\n",
      "53/65 [=======================>......] - ETA: 0s - loss: 0.0022 - accuracy: 0.9994  \n",
      "Epoch 00152: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0230 - val_accuracy: 0.9955\n",
      "Epoch 153/1000\n",
      "52/65 [=======================>......] - ETA: 0s - loss: 0.0012 - accuracy: 0.9994  \n",
      "Epoch 00153: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0292 - val_accuracy: 0.9949\n",
      "Epoch 154/1000\n",
      "50/65 [======================>.......] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997  \n",
      "Epoch 00154: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0309 - val_accuracy: 0.9949\n",
      "Epoch 155/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 7.1705e-04 - accuracy: 0.9997\n",
      "Epoch 00155: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 8.6073e-04 - accuracy: 0.9998 - val_loss: 0.0248 - val_accuracy: 0.9955\n",
      "Epoch 156/1000\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998  \n",
      "Epoch 00156: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0246 - val_accuracy: 0.9961\n",
      "Epoch 157/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0024 - accuracy: 0.9989  \n",
      "Epoch 00157: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.9990 - val_loss: 0.0262 - val_accuracy: 0.9949\n",
      "Epoch 158/1000\n",
      "49/65 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997  \n",
      "Epoch 00158: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 5ms/step - loss: 8.6142e-04 - accuracy: 0.9998 - val_loss: 0.0268 - val_accuracy: 0.9949\n",
      "Epoch 159/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 8.4387e-04 - accuracy: 0.9995\n",
      "Epoch 00159: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 7.8513e-04 - accuracy: 0.9995 - val_loss: 0.0224 - val_accuracy: 0.9949\n",
      "Epoch 160/1000\n",
      "56/65 [========================>.....] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 00160: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0255 - val_accuracy: 0.9955\n",
      "Epoch 161/1000\n",
      "59/65 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997    \n",
      "Epoch 00161: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0273 - val_accuracy: 0.9949\n",
      "Epoch 162/1000\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9988\n",
      "Epoch 00162: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0224 - val_accuracy: 0.9961\n",
      "Epoch 163/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 00163: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0239 - val_accuracy: 0.9955\n",
      "Epoch 164/1000\n",
      "58/65 [=========================>....] - ETA: 0s - loss: 0.0024 - accuracy: 0.9992    \n",
      "Epoch 00164: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 1s 8ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 0.0331 - val_accuracy: 0.9944\n",
      "Epoch 165/1000\n",
      "55/65 [========================>.....] - ETA: 0s - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 00165: val_loss did not improve from 0.01984\n",
      "65/65 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0436 - val_accuracy: 0.9938\n",
      "Epoch 00165: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e058b96970>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "RBkmDeUW9hE4"
   },
   "outputs": [],
   "source": [
    "# Loading the saved model\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxvb2Y299hE3",
    "outputId": "7015e279-0501-4f24-d1b5-90652d2de17d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 1s 3ms/step - loss: 0.0198 - accuracy: 0.9966\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation\n",
    "# TODO Test on loaded model\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tFz9Tb0I9hE4",
    "outputId": "bb8a62a9-bf7d-4d99-8099-bda4e2e1c73a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9998116e-01 1.9555956e-07 1.8631601e-05 4.9263099e-10 8.1802013e-12\n",
      " 5.5178467e-10 2.4716714e-14]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inference test\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3U4yNWx9hE4"
   },
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "AP1V6SCk9hE5",
    "outputId": "efce96b9-ca1c-44a5-ef77-58f1d5fc154c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9980    0.9942    0.9961       513\n",
      "           1     0.9936    0.9979    0.9958       470\n",
      "           2     0.9978    0.9955    0.9966       448\n",
      "           3     1.0000    1.0000    1.0000       203\n",
      "           4     1.0000    1.0000    1.0000        57\n",
      "           5     0.9750    1.0000    0.9873        39\n",
      "           6     1.0000    1.0000    1.0000        50\n",
      "\n",
      "    accuracy                         0.9966      1780\n",
      "   macro avg     0.9949    0.9982    0.9965      1780\n",
      "weighted avg     0.9966    0.9966    0.9966      1780\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    plt.xlabel('True Class')\n",
    "    plt.xlabel('Predicted Class')\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    ax.set(xlabel='Predicted', ylabel='True')\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNP6aqzc9hE5"
   },
   "source": [
    "# Convert to model for Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "ODjnYyld9hE6"
   },
   "outputs": [],
   "source": [
    "# Save as a model dedicated to inference\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRfuK8Y59hE6",
    "outputId": "106250fb-84e1-4ee8-bc8e-dcedb2bfd31c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\halor\\AppData\\Local\\Temp\\tmpxd9uxaud\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7632"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform model (quantization)\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CHBPBXdx9hE6"
   },
   "source": [
    "## Inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGAzLocO9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQuDK8YS9hE7"
   },
   "outputs": [],
   "source": [
    "# Get I / O tensor\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2_ixAf_l9hE7"
   },
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s4FoAnuc9hE7",
    "outputId": "330d050b-a3fb-41ce-fa07-dc7a48d715e7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Inference implementation\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vONjp19J9hE8",
    "outputId": "9338c9f1-499b-4e10-844d-950075e98a75"
   },
   "outputs": [],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GCHB0ELGs60"
   },
   "source": [
    "## Download model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2jM8I3jGdF6",
    "outputId": "bd2c08cc-d57c-4589-e4fa-f80389176b96"
   },
   "outputs": [],
   "source": [
    "!zip -r model.zip keypoint_classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEqyprC6cMVF"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Hyperparameters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KrjjSqlLcQ4O"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YO6VffaRcY3R"
   },
   "outputs": [],
   "source": [
    "# Init parameters to tune\n",
    "HP_NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16, 32, 64]))\n",
    "HP_NUM_UNITS_2 = hp.HParam('num_units_2', hp.Discrete([8, 16, 32]))\n",
    "HP_NUM_UNITS_3 = hp.HParam('num_units_3', hp.Discrete([8, 16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eMysvzFxctmG"
   },
   "outputs": [],
   "source": [
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS_1,HP_NUM_UNITS_2,HP_NUM_UNITS_3, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XSDYqpKZgOBw"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_save_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20120/3045730086.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Model checkpoint callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m cp_callback = tf.keras.callbacks.ModelCheckpoint(\n\u001b[1;32m----> 3\u001b[1;33m     model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Callback for early stopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mes_callback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_save_path' is not defined"
     ]
    }
   ],
   "source": [
    "# Model checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "# Callback for early stopping\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=15, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ssEmXpJcxSp"
   },
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_1], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_2], activation='relu'),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS_3], activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "  \n",
    "  model.compile(\n",
    "    optimizer=hparams[HP_OPTIMIZER],\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "  \n",
    "  cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False, save_best_only=True)\n",
    "\n",
    "  model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "               cp_callback,\n",
    "               es_callback,\n",
    "               ]\n",
    "  ) \n",
    "\n",
    "  # Load model with best accuracy\n",
    "  model = tf.keras.models.load_model(model_save_path)\n",
    "\n",
    "  _, accuracy = model.evaluate(X_test, y_test)\n",
    "  return accuracy\n",
    "\n",
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    accuracy = train_test_model(hparams)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5pO9W84DdHVL"
   },
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units_1 in HP_NUM_UNITS_1.domain.values:\n",
    "  for num_units_2 in HP_NUM_UNITS_2.domain.values:\n",
    "    for num_units_3 in HP_NUM_UNITS_3.domain.values:\n",
    "      for dropout_rate in np.arange(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 0.1):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS_1: num_units_1,\n",
    "              HP_NUM_UNITS_2: num_units_2,\n",
    "              HP_NUM_UNITS_3: num_units_3,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams)\n",
    "          session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "21knbMYldaUn"
   },
   "outputs": [],
   "source": [
    "# !ATTENTION! Works only in Colab\n",
    "# %tensorboard --logdir logs/hparam_tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J6_UH6jttBsD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf logs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Keypoint_model_training.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
